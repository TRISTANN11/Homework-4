{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "## Due October 22\n",
    "\n",
    "## 1 (20 pts) Backpropagation\n",
    "While the formulas for backpropagation that we've dealt with are generally for fairly large graphs, it's instructive to develop a little bit of intuition by performing it on very small graphs.  Consider the following graph:\n",
    "<img src=graph.png>\n",
    "where $x$ is an input, nodes with a $\\sigma$ apply the logistic function, nodes with an $I$ apply the identity function (aka don't really do anything), and $L$ is the squared error between a prediction and an observation $y$.  Written out algebraically, this graph says\n",
    "\\begin{align}\n",
    "a^{(1)}& = x w_1^{(1)} \\\\\n",
    "z^{(1)}& = \\sigma(a_1) \\\\\n",
    "[a^{(2)}_1,a^{(2)}_2]& = z^{(1)} \\times [w_1^{(2)}, w_2^{(2)}] \\\\\n",
    "[z^{(2)}_1,z^{(2)}_2]& = [\\sigma(a^{(2)}_1),\\sigma(a^{(2)}_2)] \\\\\n",
    "a^{(3)}& = z^{(2)}_1 w_1^{(3)} + z^{(2)}_2 w_2^{(3)} \\\\\n",
    "z^{(3)}& = a^{(3)} \\\\\n",
    "L &= \\frac{1}{2}(z^{(3)} - y)^2 \\\\\n",
    "\\end{align}\n",
    "The chain rule can be used to take derivatives of $L$ with respect to the various weights, even far back in the chain.  For example, we could use the chain rule to take the derivative of $L$ with respect to $w^{(3)}_1$ as follows:\n",
    "$$\n",
    "\\frac{\\partial L}{w_1^{(3)}} = \\frac{\\partial L}{\\partial z^{(3)}} \\frac{\\partial z^{(3)}}{\\partial a^{(3)}} \\frac{\\partial a^{(3)}}{\\partial w^{(3)}_1} = (z^{(3)} - y) \\times 1 \\times z^{(2)}_1\n",
    "$$\n",
    "What we've done here is to trace the path from $L$ to the parameter, taking the derivative between the outputs and inputs of each node as we work back through the graph, then evaluated each resulting derivative!\n",
    "\n",
    "### 1A \n",
    "**Derive and evaluate an expression for $$\\frac{\\partial L}{\\partial w^{(2)}_2}.$$**  Compute this derivative for the feature $x$, data $y$, and parameter values $w_j^{(l)}$ given in the following code block.  Compare your results to the [finite difference approximation](https://en.wikipedia.org/wiki/Finite_difference_method) of this derivative computed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 1.0      # Single feature\n",
    "w_11 = 0.5   # Parameters\n",
    "w_12 = 0.7\n",
    "w_22 = -0.3\n",
    "w_13 = 0.1\n",
    "w_23 = -0.8\n",
    "y = 0.5      # Single data point\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(a):\n",
    "    return 1./(1+np.exp(-a))\n",
    "\n",
    "# Forward pass\n",
    "def forward(x):\n",
    "    a_1 = x*w_11\n",
    "    z_1 = sigmoid(a_1)\n",
    "    a_12,a_22 = z_1*w_12,z_1*w_22\n",
    "    z_12,z_22 = sigmoid(a_12),sigmoid(a_22)\n",
    "    a_3 = z_12 * w_13 + z_22 * w_23\n",
    "    z_3 = a_3\n",
    "    L = 0.5*(z_3 - y)**2\n",
    "    return L\n",
    "\n",
    "# Compute the forward pass\n",
    "L_0 = forward(x)\n",
    "\n",
    "# Very slightly change the value of w_22\n",
    "w_22 += 1e-5\n",
    "\n",
    "# Compute the forward pass again\n",
    "L_1 = forward(x)\n",
    "\n",
    "# Compute Delta L / Delta w_22 as an approximation for the derivative\n",
    "dLdw22_fd = (L_1 - L_0)/1e-5\n",
    "\n",
    "# Reset w_22 to its previous value\n",
    "w_22 -= 1e-5\n",
    "print('The finite difference approximation to dL/dw_2^2 is: ',dLdw22_fd)\n",
    "\n",
    "#! Your function to evaluate the derivative symbolically goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B (FOR GRAD STUDENTS ONLY)\n",
    "**Why shouldn't we just use the finite difference method like the one shown above to compute gradients?  Why is backpropagation useful?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C (FOR GRAD STUDENTS ONLY) \n",
    "**Use the chain rule to determine an expression for**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1^{(1)}}\n",
    "$$\n",
    "This one is a little bit harder because there are *two paths* from $w_1^{(1)}$ to $L$ in the graph (unlike in Part 1A)!  There are many ways to deal with this if you have the calculus background to do it, but perhaps the most intuitive way (and what automatic differentiation systems do) is to evaluate the chain rule for both paths and *sum them*.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Facial Recognition\n",
    "\n",
    "The same type of neural network that we've been using to classify digits can just as easily be used to classify other image datasets.  A particularly fun and easy dataset to work with is called the [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) dataset, which contains a large database of cropped grayscale images with associated labels (i.e. names).  We can download it using sklearn.datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch LFW dataset, ensuring that we have at least 50 images per class (i.e. per person)\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=50, resize=0.4)\n",
    "\n",
    "# Extract number of data points, and the height and width of the images for later reshaping\n",
    "m, h, w = lfw_people.images.shape\n",
    "n = h*w\n",
    "\n",
    "# Extract number of classes\n",
    "N = len(lfw_people.target_names)\n",
    "\n",
    "# Split the training and test set\n",
    "X,X_test,y,y_test = train_test_split(lfw_people.data,lfw_people.target)\n",
    "X/=255.\n",
    "X_test/=255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A Facial Recognition System (40 pts)\n",
    "\n",
    "**Using the MNIST classifier we developed in pytorch for class as a basis for development, create a new classifier that inputs faces and outputs names.**  \n",
    "- 1) you'll have to change some things, in particular the number of input features, the number of hidden layer nodes, and also the number of classes!  \n",
    "- 2) To begin with, use only 8 nodes in your hidden layer.\n",
    "- 3) Adjust the learning rate, number of epochs, and batch size so that you're confident the network is converged, based either on the cost function or on the test set accuracy\n",
    "\n",
    "**Train your classifier and report your test set accuracy!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B Model Selection (20pts)\n",
    "We began with a relatively simple model that had only 8 hidden nodes.  If we increase that number do we get better predictive accuracy on the test set?  **Re-run your model using 16 hidden layer nodes.  Is the increase in model complexity (and computing effort) justified?  Why or why not?**  If you answered yes to the previous question, double the number of nodes again, and answer the same questions.  **What is the maximum number of hidden layer nodes that is justified for this task?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C Feature selection visualization (20 pts)\n",
    "As in our experiments with MNIST, we're interested in determining exactly what features this neural network is extracting from the raw input data.  **Extract the weight matrix between the input and hidden layer, then reshape and visualize a few of them as images** (note the image width and height parameters defined when we loaded the data).  **Comment on the types of features that this neural network is paying attention to.**\n",
    "\n",
    "- Note 1) We can extract parameters from our Model class (and transform them into numpy arrays) with the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.cpu().detach().numpy() for p in model.l1.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note 2) Pytorch defines the linear transformation between activation layers using matrices that are transposed relative to how we've seen it so far, i.e. as  \n",
    "$$\n",
    "A = X W^T + B^T\n",
    "$$\n",
    "This means that you'll want to extract and reshape *rows* rather than *columns* of this weight matrix for visualization as an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
